The file describes the instructions to install the framework on the BOSS MOOL operating System  (Kernel Version 3.16)

NOTE: Make sure that the system has proper internet connectivity.

1. Git clone the Scheduler in /home/<hostname>. Open the folder /home/<hostname>/ConBalancer/Scheduler
2. Run the file : sh ./install_docker.sh
3. Check whether Docker is installed properly through command : docker version.
Make sure that the Experimental Version is set to true and installed docker vers
ion is 1.13.0.
4. Run:  sudo sh ./home/<hostname>/ConBalancer/Scheduler/install.sh
5. Make sure that CRIU is installed. Execute the command: systemctl show. The command shows the CRIU installed under the ENVIRONMENT attribute. If CRIU is properly installed the ENVIRONMENT path will show the CRIU installed path as /home/<HOSTNAME>/criu-3.4/. Try running criu command to see if its properly installed: criu. If criu command executes then the CRIU is installed properly.
6. If some issues are occured run, systemctl restart docker. Also change the permission of /var/run/docker.sock to all i.e chmod 777 /var/run/docker.sock.
7. mv /home/<hostname>/ConBalancer/Scheduler /opt
8. cd /opt
9. tar -zxvf kafka_updated.tar
10. Establish SSH to all machines. Set the user names and user IP address of all machines in files user_IPS and user_name.
11. Execute ./ssh-all.sh
12. Add the machines and ip address in /etc/hosts file. Also add the registry IP address to the file.
12. Now run a docker container.Example : docker run -d --name tomcatdemo tomcat:alpine
13. If the registry is running, migrate the container: ./migrate_v2.sh <tomcatdemo> targetnode@ipaddress registrynode:443/

 To start a registry: 
1. mkdir -p certs && openssl req  -newkey rsa:4096 -nodes -sha256 -keyout certs/domain.key  -x509 -days 365 -out certs/domain.crt

2. docker run -d  --name registry  -v /home/<hostname>/certs:/certs   -e REGISTRY_HTTP_ADDR=0.0.0.0:443   -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt   -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key   -p 443:443 registry:2 



Create kafka and zookeeper nodes. Treat the nodes as a manager for all worker nodes. Configure setting of kafka and zookeeper as per the ip address.
On each node, start zookeeper and kafka broker node by: ./start_zk.sh and ./start_kafka.sh

Configure the file user_ips and user_name in the manager node. 

Start listener on all worker node from manager node: 
./start_listeners,sh

Start producer on all worker nodes from manager node:
./start_producerts.sh

To start optimizer go to src folder and run:

/opt/java/jdk1.8.0_144/bin/java -Dfile.encoding=UTF-8 -classpath /home/gas/Projects/ConBalancer/Scheduler/bin:/opt/kafka_2.11-0.9.0.0/libs/aopalliance-repackaged-2.4.0-b31.jar:/opt/kafka_2.11-0.9.0.0/libs/argparse4j-0.5.0.jar:/opt/kafka_2.11-0.9.0.0/libs/connect-api-0.9.0.0.jar:/opt/kafka_2.11-0.9.0.0/libs/connect-file-0.9.0.0.jar:/opt/kafka_2.11-0.9.0.0/libs/connect-json-0.9.0.0.jar:/opt/kafka_2.11-0.9.0.0/libs/connect-runtime-0.9.0.0.jar:/opt/kafka_2.11-0.9.0.0/libs/hk2-api-2.4.0-b31.jar:/opt/kafka_2.11-0.9.0.0/libs/hk2-locator-2.4.0-b31.jar:/opt/kafka_2.11-0.9.0.0/libs/hk2-utils-2.4.0-b31.jar:/opt/kafka_2.11-0.9.0.0/libs/jackson-annotations-2.5.0.jar:/opt/kafka_2.11-0.9.0.0/libs/jackson-core-2.5.4.jar:/opt/kafka_2.11-0.9.0.0/libs/jackson-databind-2.5.4.jar:/opt/kafka_2.11-0.9.0.0/libs/jackson-jaxrs-base-2.5.4.jar:/opt/kafka_2.11-0.9.0.0/libs/jackson-jaxrs-json-provider-2.5.4.jar:/opt/kafka_2.11-0.9.0.0/libs/jackson-module-jaxb-annotations-2.5.4.jar:/opt/kafka_2.11-0.9.0.0/libs/javassist-3.18.1-GA.jar:/opt/kafka_2.11-0.9.0.0/libs/javax.annotation-api-1.2.jar:/opt/kafka_2.11-0.9.0.0/libs/javax.inject-1.jar:/opt/kafka_2.11-0.9.0.0/libs/javax.inject-2.4.0-b31.jar:/opt/kafka_2.11-0.9.0.0/libs/javax.servlet-api-3.1.0.jar:/opt/kafka_2.11-0.9.0.0/libs/javax.ws.rs-api-2.0.1.jar:/opt/kafka_2.11-0.9.0.0/libs/jersey-client-2.22.1.jar:/opt/kafka_2.11-0.9.0.0/libs/jersey-common-2.22.1.jar:/opt/kafka_2.11-0.9.0.0/libs/jersey-container-servlet-2.22.1.jar:/opt/kafka_2.11-0.9.0.0/libs/jersey-container-servlet-core-2.22.1.jar:/opt/kafka_2.11-0.9.0.0/libs/jersey-guava-2.22.1.jar:/opt/kafka_2.11-0.9.0.0/libs/jersey-media-jaxb-2.22.1.jar:/opt/kafka_2.11-0.9.0.0/libs/jersey-server-2.22.1.jar:/opt/kafka_2.11-0.9.0.0/libs/jetty-http-9.2.12.v20150709.jar:/opt/kafka_2.11-0.9.0.0/libs/jetty-io-9.2.12.v20150709.jar:/opt/kafka_2.11-0.9.0.0/libs/jetty-security-9.2.12.v20150709.jar:/opt/kafka_2.11-0.9.0.0/libs/jetty-server-9.2.12.v20150709.jar:/opt/kafka_2.11-0.9.0.0/libs/jetty-servlet-9.2.12.v20150709.jar:/opt/kafka_2.11-0.9.0.0/libs/jetty-util-9.2.12.v20150709.jar:/opt/kafka_2.11-0.9.0.0/libs/jopt-simple-3.2.jar:/opt/kafka_2.11-0.9.0.0/libs/kafka_2.11-0.9.0.0.jar:/opt/kafka_2.11-0.9.0.0/libs/kafka_2.11-0.9.0.0-javadoc.jar:/opt/kafka_2.11-0.9.0.0/libs/kafka_2.11-0.9.0.0-scaladoc.jar:/opt/kafka_2.11-0.9.0.0/libs/kafka_2.11-0.9.0.0-sources.jar:/opt/kafka_2.11-0.9.0.0/libs/kafka_2.11-0.9.0.0-test.jar:/opt/kafka_2.11-0.9.0.0/libs/kafka-clients-0.9.0.0.jar:/opt/kafka_2.11-0.9.0.0/libs/kafka-log4j-appender-0.9.0.0.jar:/opt/kafka_2.11-0.9.0.0/libs/kafka-tools-0.9.0.0.jar:/opt/kafka_2.11-0.9.0.0/libs/log4j-1.2.17.jar:/opt/kafka_2.11-0.9.0.0/libs/lz4-1.2.0.jar:/opt/kafka_2.11-0.9.0.0/libs/metrics-core-2.2.0.jar:/opt/kafka_2.11-0.9.0.0/libs/osgi-resource-locator-1.0.1.jar:/opt/kafka_2.11-0.9.0.0/libs/scala-library-2.11.7.jar:/opt/kafka_2.11-0.9.0.0/libs/scala-parser-combinators_2.11-1.0.4.jar:/opt/kafka_2.11-0.9.0.0/libs/scala-xml_2.11-1.0.4.jar:/opt/kafka_2.11-0.9.0.0/libs/slf4j-api-1.7.6.jar:/opt/kafka_2.11-0.9.0.0/libs/slf4j-log4j12-1.7.6.jar:/opt/kafka_2.11-0.9.0.0/libs/snappy-java-1.1.1.7.jar:/opt/kafka_2.11-0.9.0.0/libs/validation-api-1.1.0.Final.jar:/opt/kafka_2.11-0.9.0.0/libs/zkclient-0.7.jar:/opt/kafka_2.11-0.9.0.0/libs/zookeeper-3.4.6.jar ConsumerLoop


To stop all containers from the manager: 
./stopcon_global.sh

Stooping producers or consumers:
./stop_listeners.sh
./stop_producers.sh 


Experiment test:
Configure the SWARM cluster. Create any one node as Swarm manager node among all workers by: docker swarm init
Fetch the token to join from manager node: docker swarm join-token worker

Join all other slave nodes to the manager worker node by the token: docker swarm join --token <TOKEN>

swarm_test.sh and swarm_stop.sh files should be configured for any test workload. 
 
 
 
Details for each of the scripts used in the system.

1. Starting/Stopping Zookeeper and Kafka nodes(Brokers)

start/stop_zk and start/stop_kafka.sh: Starting the zookeeper and Kafka server on the local system.

dis_initiate.sh: Kill the Kafka server and Zookeeper server form one system. (Needs configuration)

Delete_logs.sh: Responsible for removing all logs. Better to stop zookeeper and Kafka server and remove all logs. (Extreme). Use on each system separately.


2. Starting and stopping producers/consumers.

start_producers.sh: Starts producers on all machines (uses read_dockerstats.sh) Based on user_ips and user_names files. The user needs to configure these files for each worker node.
stop_producers .sh: Stops Kafka producers across all machines

start_listeners.sh: Starts Listener on every worker node.

stop_listeners.sh: Stops the Listener on every node.

3. Script file for migrating container

migrate_v2: For migrating using the local registry. (faster)

migrate_v1 .sh: Full migration involving file system. (slower)

read_dockerstats.sh: Gets all container stats along with the system information. (LOCAL) 

4. Docker-related scripts:

runcontainer.sh: Runs containers on all nodes.

stopcon_global.sh: Stops and removes containers from all worker nodes.

run.sh: Configure what containers to run on each node.

run_scheduler.sh: Executes then container balancer algorithm. The code is present in the "src" folder.

read_logs.sh: For reading container related data (bogo operations per second).

5. Installation and configuration scripts:

install_docker.sh: Installing docker on the machine.

install.sh: Installing CRIU-v4 on the system. Updates bashrc and zookeeper configuration files. Run after install_docker.sh

sys_update.sh: Updates permission and PATH after Docker restarts. Updates systemctl which is required.

MachineId and MachineInfo: Configure these files for every system.
Configure zookeeper and Kafka server as needed along with IP address and ID. Required files (config/server.properties and config/zookeeper.properties) 
 